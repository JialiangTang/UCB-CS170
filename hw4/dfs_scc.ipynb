{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edbd020",
   "metadata": {},
   "source": [
    "## Depth First Search and Strongly Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd894fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.0 which is incompatible.\r\n",
      "fenics-dolfin 2019.1.0 requires pybind11==2.2.4, but you have pybind11 2.9.2 which is incompatible.\r\n",
      "dbt-core 1.3.0 requires networkx<3,>=2.3; python_version >= \"3.8\", but you have networkx 3.1 which is incompatible.\r\n",
      "datasets 2.2.1 requires pyarrow>=6.0.0, but you have pyarrow 5.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f07432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import otter\n",
    "assert (\n",
    "    otter.__version__ >= \"4.4.1\"\n",
    "), \"Please reinstall the requirements and restart your kernel.\"\n",
    "import networkx as nx\n",
    "import typing\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "grader = otter.Notebook(\"dfs_scc.ipynb\")\n",
    "\n",
    "rng_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178cbe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test cases\n",
    "file_path = \"generated_testcases.pkl\"\n",
    "\n",
    "# Load the variables from the pickle file\n",
    "with open(file_path, \"rb\") as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "file.close()\n",
    "inputs, outputs = loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14493076",
   "metadata": {},
   "source": [
    "#### Representing graphs in code\n",
    "\n",
    "There are multiple ways to represent graphs in code. In class we covered [adjacency matrices](https://people.eecs.berkeley.edu/~vazirani/algorithms/chap3.pdf#page=2) and [adjacency lists](https://people.eecs.berkeley.edu/~vazirani/algorithms/chap3.pdf#page=3). There is also the edge list representation, in which you store the edges in a single 1 dimensional list. In general for CS170 and in most cases, we choose to use the adjacency list representation since it allows us to efficiently search over a node's neighbors.\n",
    "\n",
    "In many programming problems, verticies are typically labelled $0$ through $n-1$ for convenience (recall that arrays and lists in most languages begin at index 0). This allows us to represent an adjacency list using a list of lists that store ints. Given an edge list, the following code will create an adjacency list for an **unweighted directed graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce91dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adj_list(n, edge_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        n:int = number of nodes in the graph. The nodes are labelled with integers 0 through n-1\n",
    "        edge_list:List[Tuple(int,int)] = edge list where each tuple (u,v) represents the directed \n",
    "            edge (u,v) in the graph\n",
    "    return:\n",
    "        A List[List[int]] representing the adjacency list \n",
    "    \"\"\"\n",
    "    adj_list = [[] for i in range(n)] \n",
    "    for u, v in edge_list:\n",
    "        adj_list[u].append(v)\n",
    "    for nodes in adj_list:\n",
    "        nodes.sort()\n",
    "    return adj_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9884119",
   "metadata": {},
   "source": [
    "### Q1) Depth First Search\n",
    "In this question, you will have to implement a DFS traversal for the given adj_list. As you traverse the graph, you should update a prev array, where prev[v] = u if you came to v from u. Return this list prev. By default prev[start] should equal start. \n",
    "\n",
    "**For all subparts, your DFS should prioritize visiting lower valued vertices first.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b598c",
   "metadata": {},
   "source": [
    "> **Task 1.1**\n",
    ">* Given a graph represented as an adjacency list, perform a DFS traversal that prioritizes visiting the lower valued nodes first\n",
    ">* Return a list of length=number of nodes where the ith element in this list contains the node that explored node i. If node i is the root of the dfs tree, then the ith element should be node i.\n",
    ">* Make sure to traverse every node present in the graph, even if the graph is disconnected.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee95cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dfs(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        A List[int] where the ith element represents the node that called dfs(i). If a \n",
    "            DFS is started from a vertex, then List[i] = i.\n",
    "    \"\"\"\n",
    "    def explore(adj_list, u):\n",
    "        visited[u] = 1\n",
    "        for v in adj_list[u]:\n",
    "            if visited[v] == 0:\n",
    "                res[v] = u\n",
    "                explore(adj_list, v)\n",
    "            \n",
    "    n = len(adj_list)\n",
    "    visited = [0]*n\n",
    "    res = [0]*n\n",
    "    for i in range(n):\n",
    "        if not visited[i]:\n",
    "            res[i] = i\n",
    "            explore(adj_list, i)\n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee5a3058",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test 1.1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 4832.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed! ðŸš€</p>"
      ],
      "text/plain": [
       "q1.1 results: All test cases passed!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af5e5af",
   "metadata": {},
   "source": [
    "#### Pre and Postorder Values\n",
    "\n",
    "In class we showed how to use DFS to check if there exists a path between two nodes, topologically sort nodes, and find SCC's. In those algorithms, pre and post numbers were crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3d5dd",
   "metadata": {},
   "source": [
    ">**Task 1.2**\n",
    ">* Rework your implementation of DFS in this next cell to allow it to generate pre and post order numbers for each node.\n",
    ">* Your smallest preorder number should be 1. Your largest postorder number should be  $ 2 \\times \\text{(number of vertices)}$.\n",
    ">* Return two lists of tuples. Each list should contain a tuple of two values Tuple(Node, Time Visited). The first list should contain the tuples with the preorder visits, and the second list should contain the tuples with the postorder visits.\n",
    ">* We have provided some boiler plate code to get you started. Feel free to write your own if you find that easier.\n",
    ">* Feel free to refer to Figure 3.6(b) in section 3.2.3 of the DPV notes for how your pre and post order values should look like.\n",
    ">>* If the input was the left most component, you should return [(A, 1), (B, 2), (E, 4), (I, 5), (J, 6)], [(B, 3), (J, 7), (I, 8), (E, 9), (A, 10)].\n",
    ">>* Both lists should be sorted according to the second element in the tuple.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12ff79ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# time = 1\n",
    "def get_pre_post(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        List[Tuple(int, int)], List[Tuple(int, int)] representing the pre and post order values\n",
    "            respectively. Each tuple should have a vertex as its first entry, and the pre/post order\n",
    "            value as its second entry.\n",
    "    \"\"\"\n",
    "    time = 1\n",
    "    pre = []\n",
    "    post = []\n",
    "    def explore_mem(adj_list, u):\n",
    "        nonlocal time\n",
    "        visited[u] = 1\n",
    "        pre.append((u, time))\n",
    "        time += 1\n",
    "        for v in adj_list[u]:\n",
    "            if visited[v] == 0:\n",
    "                res[v] = u\n",
    "                explore_mem(adj_list, v)\n",
    "        post.append((u, time))\n",
    "        time += 1    \n",
    "        # return time\n",
    "            \n",
    "    n = len(adj_list)\n",
    "    visited = [0]*n\n",
    "    res = [0]*n\n",
    "    for i in range(n):\n",
    "        if not visited[i]:\n",
    "            res[i] = i\n",
    "            explore_mem(adj_list, i)\n",
    "    pre = sorted(pre, key=lambda x:x[1])\n",
    "    post = sorted(post, key=lambda x:x[1])\n",
    "    return pre, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bfaf07e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test 1.2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 8698.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.2</pre></strong> passed! ðŸŽ‰</p>"
      ],
      "text/plain": [
       "q1.2 results: All test cases passed!"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873ac38",
   "metadata": {},
   "source": [
    "#### Tree, Forward, Back, Cross Edges\n",
    "\n",
    "As we perform DFS traversals and create DFS trees and DFS forests within our graph, we would like to classify our edges according to how they appear in the resulting DFS forest. These classifications can provide us with insights about our graph. For example, the presence of a back edge (u, v) tells us that we have a cycle within this graph that includes all the tree edges on the path from v to u and the back edge (u, v)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a556b",
   "metadata": {},
   "source": [
    ">**Task 1.3**\n",
    ">* Given the adjacency list of a graph, add each edge present in the edge set to the correct classification according the DFS traversal you implemented in part 1.\n",
    ">* Don't modify the initialization of the edges_lookup dictionary.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75500627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorize_edges(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        Dictionary({\n",
    "            'tree': set(),\n",
    "            'forward': set(),\n",
    "            'cross': set(),\n",
    "            'back': set()  \n",
    "        }) where each set() contains the edges that belong to the corresponding edge type\n",
    "    \"\"\"\n",
    "    \n",
    "    def explore_tree(adj_list, u):\n",
    "        visited[u] = 1\n",
    "        for v in adj_list[u]:\n",
    "            if not visited[v]:\n",
    "                edges_lookup['tree'].add((u, v))\n",
    "                explore_tree(adj_list, v)\n",
    "    \n",
    "    edges_lookup = {\n",
    "        'tree': set(),\n",
    "        'forward': set(),\n",
    "        'cross': set(),\n",
    "        'back': set()\n",
    "    }\n",
    "    n = len(adj_list)\n",
    "    visited = [0]*n\n",
    "    \n",
    "    # re-arrange pre and post\n",
    "    pre, post = get_pre_post(adj_list)[0], get_pre_post(adj_list)[1]\n",
    "    pre = sorted(pre, key = lambda x:x[0])\n",
    "    post = sorted(post, key = lambda x:x[0])\n",
    "    \n",
    "    # find all tree edges\n",
    "    for u in range(n):\n",
    "        if not visited[u]:\n",
    "            visited[u] = 1\n",
    "            for v in adj_list[u]:\n",
    "                explore_tree(adj_list, u)\n",
    "            \n",
    "    # find all forward, cross and back edges\n",
    "    for u in range(n):\n",
    "        for v in adj_list[u]:\n",
    "            if post[u][1] < post[v][1] and pre[u][1] > pre[v][1]:\n",
    "                edges_lookup['back'].add((u, v))\n",
    "            elif post[u][1] > post[v][1] and pre[u][1] > pre[v][1]:\n",
    "                edges_lookup['cross'].add((u, v))\n",
    "            elif post[u][1] > post[v][1] and pre[u][1] < pre[v][1] and (u ,v) not in edges_lookup['tree']:\n",
    "                edges_lookup['forward'].add((u, v))\n",
    "    # print(edges_lookup['tree'])\n",
    "    return edges_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18be0278",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test 1.3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 745.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.3</pre></strong> passed! ðŸŒŸ</p>"
      ],
      "text/plain": [
       "q1.3 results: All test cases passed!"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89220a",
   "metadata": {},
   "source": [
    "### Q2) Strongly Connected Components\n",
    "\n",
    "We will now see how we can tie the concepts of DFS traversals and pre/post order values to obtain the strongly conencted components within a graph. SCC meta graphs are useful in that they allow us to construct DAGs, linearize a graph that contains cycles and obtain equivalence classes within a graph among other use cases.\n",
    "\n",
    "S. Rao Kosaraju solved this problem of finding the SCCs within a graph in 1978 with the Kosaraju-Sharir Algorithm (which is the algorithm presented in the DPV notes section 3.4.2). The first step of this algorithm is to reverse the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796304f",
   "metadata": {},
   "source": [
    "> **Task 2.1**\n",
    ">* Given a graph represented as an adjacency list, return the acjacency list that represents the reversed graph (the vertex set is the same as the input graph, the edge set contains (v, u) if and only if (u, v) is present in the input graph's edge set).\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4beede0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_graph(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        List[List[int]] representing the adjacency list of the reversed input graph\n",
    "    \"\"\"\n",
    "    reversed_adj_list = [[] for i in range(len(adj_list))]\n",
    "    for u in range(len(adj_list)):\n",
    "        for v in adj_list[u]:\n",
    "            reversed_adj_list[v].append(u)\n",
    "    return reversed_adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ac9d500",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test 2.1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 8006.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed! ðŸ’¯</p>"
      ],
      "text/plain": [
       "q2.1 results: All test cases passed!"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8efa5",
   "metadata": {},
   "source": [
    "Now, you get to complete the rest of the algorithm to find the SCCs within a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd60546",
   "metadata": {},
   "source": [
    "> **Task 2.2**\n",
    ">* Given a graph represented as an adjacency list, return a list of SCC components.\n",
    ">* The SCC components should be represented as sets that contain only the nodes present in that SCC.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a65d4fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_SCCs(adj_list):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        adj_list:List[List[int]] = the adjacency list that represents our input graph\n",
    "    return:\n",
    "        List(Set(int, ...), ...) a list of sets where each set contains all the nodes \n",
    "            that belong to the corresponding SCC\n",
    "    \"\"\"\n",
    "    def explore_scc(adj_list, u):\n",
    "        visited[u] = 1\n",
    "        scc.add(u)\n",
    "        for v in adj_list[u]:\n",
    "            if visited[v] == 0:\n",
    "                explore_scc(adj_list, v)\n",
    "    \n",
    "    scc_list = []\n",
    "    # sccs = set()\n",
    "    re_adj_list = reverse_graph(adj_list)\n",
    "    # get pre and post\n",
    "    pre, post = get_pre_post(re_adj_list)[0], get_pre_post(re_adj_list)[1]\n",
    "    # pre = sorted(pre, key = lambda x:x[0])\n",
    "    post.reverse()\n",
    "    \n",
    "    n = len(adj_list)\n",
    "    visited = [0]*n\n",
    "    for i in range(n):\n",
    "        scc = set()\n",
    "        u = post[i][0]\n",
    "        if not visited[u]:\n",
    "            explore_scc(adj_list, u)\n",
    "            scc_list.append(scc)\n",
    "    return scc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e0ea37c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test 2.2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 1553.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed! ðŸ™Œ</p>"
      ],
      "text/plain": [
       "q2.2 results: All test cases passed!"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6093e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65327758",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab549f",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "otter": {
   "OK_FORMAT": false,
   "assignment_name": "dfs_scc",
   "tests": {
    "q1.1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q1.1\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q1i(dfs, inputs, outputs, tqdm, env):\n    for i in tqdm(range(0, 100), desc =\"Running Test 1.1\"):\n        prevStudent = dfs(inputs['q1.1'][i])\n        expectedOutput = outputs['q1.1'][i]\n        assert len(prevStudent) == len(expectedOutput), \"Check that you are setting a value for each node\"\n        for u, v in enumerate(expectedOutput):\n            assert prevStudent[u] == v, f\"wrong value for node {u}\"\n\n",
    "q1.2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q1.2\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q1ii(get_pre_post, inputs, outputs, tqdm, env):\n    for i in tqdm(range(0, 100), desc =\"Running Test 1.2\"):\n        input_adjlist = inputs['q1.2'][i]\n        preStudent, postStudent = get_pre_post(input_adjlist)\n        expectedPre, expectedPost = outputs['q1.2'][i]\n        assert len(expectedPre) == len(preStudent) and len(expectedPost) == len(postStudent), 'make sure to set pre and post for each node'\n        for j in range(len(expectedPre)):\n            assert len(preStudent[j]) == 2, 'Make sure each value is (node, pre/post order)'\n            assert preStudent[j] == expectedPre[j], f'wrong preorder value for node {preStudent[j][0]}'\n        for j in range(len(expectedPost)):\n            assert len(postStudent[j]) == 2, 'Make sure each value is (node, pre/post order)'\n            assert postStudent[j] == expectedPost[j], f'wrong preorder value for node {postStudent[j][0]}'\n\n",
    "q1.3": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q1.3\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q1iii(categorize_edges, inputs, outputs, tqdm, env):\n    for i in tqdm(range(0, 100), desc =\"Running Test 1.3\"):\n        input_adjlist = inputs['q1.3'][i]\n        expected_edge_dict = outputs['q1.3'][i]\n        edge_dict = categorize_edges(inputs['q1.3'][i])\n        for edge_type in expected_edge_dict:\n            assert expected_edge_dict[edge_type] == edge_dict[edge_type], f'returned wrong set of {edge_type} edges'\n\n",
    "q2.1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.1\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q2i(reverse_graph, inputs, outputs, tqdm, env):\n    for i in tqdm(range(0, 100), desc =\"Running Test 2.1\"):\n        reversed_graph = reverse_graph(inputs['q2.1'][i])\n        assert reversed_graph == outputs['q2.1'][i], 'wrong adjacency list returned for the reversed graph'\n\n",
    "q2.2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.2\"\npoints = 2\n\n@test_case(points=None, hidden=False)\ndef test_q2ii(find_SCCs, inputs, outputs, tqdm, env):\n    for i in tqdm(range(0, 100), desc =\"Running Test 2.2\"):\n        scc_list = find_SCCs(inputs['q2.2'][i])\n        scc_sets = {frozenset(c) for c in scc_list}\n        assert scc_sets == outputs['q2.2'][i], 'wrong SCCs found'\n\n"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
